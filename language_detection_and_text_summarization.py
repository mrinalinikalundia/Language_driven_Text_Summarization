# -*- coding: utf-8 -*-
"""language detection and text summarization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rfSzlGPbCqcC6Hgk10Mf1L6qoF8FGbB_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/Language Detection.csv.zip')

df

df.isna().sum()

df[df.duplicated()]

df.drop(df[df.duplicated()].index, axis=0, inplace=True)

df.shape

df["Language"].nunique()

df.Language.value_counts()

plt.figure(figsize=(20,8))

total= float(len(df['Language']))
ax= sns.countplot(x= 'Language', data= df, order= df['Language'].value_counts().index, palette= 'pastel')

for p in ax.patches:
    percentage= '{:.2f}%'.format(100 * p.get_height()/total)
    x= p.get_x() + p.get_width()
    y= p.get_height()
    ax.annotate(percentage, (x, y), fontsize=16, ha='center')
    
plt.title('Counts and Percentages of Languages', fontsize=24)
plt.xlabel("Language",fontsize=20)
plt.ylabel("Count", fontsize=20)
plt.xticks(size= 18, rotation=90) 
plt.show()

df1= df.copy()
df1['cleaned_Text']= ""
df1

import re
def clean_function(Text):
    # removing the symbols and numbers
    Text = re.sub(r'[\([{})\]!@#$,"%^*?:;~`0-9]', ' ', Text)
    
    # converting the text to lower case
    Text = Text.lower()
    Text = re.sub('http\S+\s*', ' ', Text)  # remove URLs
    Text = re.sub('RT|cc', ' ', Text)  # remove RT and cc
    Text = re.sub('#\S+', '', Text)  # remove hashtags
    Text = re.sub('@\S+', '  ', Text)  # remove mentions
    Text = re.sub('\s+', ' ', Text)  # remove extra whitespace
    
    return Text

df1['cleaned_Text'] = df1['Text'].apply(lambda x: clean_function(x))
df1

X= df1["cleaned_Text"]
y= df1["Language"]

from sklearn.preprocessing import LabelEncoder
encoder= LabelEncoder()
y= encoder.fit_transform(y)
y.shape

from sklearn.feature_extraction.text import CountVectorizer
CV= CountVectorizer()
X= CV.fit_transform(X).toarray()
X.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=42)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB

models = {
    'K-Nearest Neighbors' : KNeighborsClassifier(),
    'Random Forest' : RandomForestClassifier(),
    'MNB' : MultinomialNB()    
}

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for name, model in models.items():
#     print(f'{name} training started...')
#     model.fit(X_train, y_train)
#     print(f'{name} trained')

y_pred = model.predict(X_test)

y_pred

from sklearn.metrics import accuracy_score 
from sklearn.metrics import confusion_matrix as CM
from sklearn.metrics import classification_report

# Commented out IPython magic to ensure Python compatibility.
# %%time
# for name in models:
#     acc_score= round(accuracy_score(y_test, models.get(name).predict(X_test)), 3)
#     print(f'{name} accuracy score :  {acc_score}')

for name in models:
    print(f'{name} classification report')
    print("-------------------------------")
    print(classification_report(y_test, models.get(name).predict(X_test)))
    print("******************************")
    print(" ")

for name in models:
    print(f'{name} ConfusionMatrix')
    predictions= models.get(name).predict(X_test)
    score = round(accuracy_score(y_test, models.get(name).predict(X_test)), 3)
    confusionMatrix = CM(y_test, models.get(name).predict(X_test))
    sns.heatmap(confusionMatrix, annot=True, fmt=".0f")
    plt.xlabel('Actual Values')
    plt.ylabel('Prediction Values')
    plt.title('Accuracy Score: {0}'.format(score), size = 15)
    plt.show()
    print("******************************")
    print(" ")

def prediction(text):
    x= CV.transform([text]).toarray()
    lang= model.predict(x)
    lang= encoder.inverse_transform(lang)
    print("This word/sentence contains {} word(s).".format(lang[0]))

prediction("до свидания ")

prediction("Η μνήμη σας βελτιώνεται καθώς μαθαίνετε μια γλώσσα. ")

prediction("ನಿಮ್ಮ ಮೆದುಳು ಸ್ವಯಂಚಾಲಿತವಾಗಿ ಅನುವಾದಿಸುವುದರಿಂದ ")

#Predict and Summarize the Text

# This is the inital text of the full text
prediction("Appellant, Kawas Manekshaw Nanavati , a commander in the Indian Navy was charged for murder of deceased Prem Ahuja under section 302 and 304, part 1 of IPC. When the appellant was away for his work, his wife, Sylvia, nurtured an illicit relationship with Mr. Ahuja, a friend of Nanavati. On 27th April 1959 , Nanavati returned from one of his long voyages. ")

!pip install -q bert-extractive-summarizer
!pip install -q spacy==2.1.3
!pip install -q transformer==2.2.2
!pip install -q neuralcoref

from summarizer import Summarizer
from pprint import pprint

text="""Appellant, Kawas Manekshaw Nanavati , a commander in the Indian Navy was charged for murder of deceased Prem Ahuja under section 302 and 304, part 1 of IPC. When the appellant was away for his work, his wife, Sylvia, nurtured an illicit relationship with Mr. Ahuja, a friend of Nanavati.
On 27th April 1959 , Nanavati returned from one of his long voyages. When he came home, his wife seemed to be behaving strangely and was not responsive or affectionate to him. Sensing something, he asked, to which Sylvia confessed about her affair with Ahuja. That evening, Nanavati dropped Sylvia (wife) and their two children at a cinema hall and went to confront Ahuja. He first went to his ship, collected his pistol on a false pretext from the stores along with six bullets, completed his official duties and continued for Prem Ahuja's office. On not finding him there, he made his way to Ahuja's home where he found Ahuja. There was a verbal confrontation between the two men. After the confrontation, there was an altercation after which three shots were fired and Prem Ahuja dropped dead. Nanavati headed straight to confess to the Provost Marshal of the Western Naval Command and later turned himself over to the Deputy Commissioner of Police.
The jury found him not guilty of murder which did not find favour with the Sessions Judge and he referred the case to Bombay High Court. The Bombay High Court dismissed the Jury's decision and convicted Nanavati under section 302 and 304 Part 1 of IPC.
Nanavati filed an appeal before the Supreme Court.
The issue of the case was whether Nanavati shot Ahuja in the "heat of the moment" or whether it was a premeditated murder which will determine the conviction of Nanavati.
The first contention that was raised was that Ahuja had just come out of the shower wearing towel. When his body was discovered, his towel was still intact on his body. It had neither loosened nor fallen off which was highly improbable in case of a scuffle. Moreover, after Sylvia's confession, a calm and collected Nanavati took them to a movie hall, dropped them there and then went to his shop to retrieve his pistol, that too under a false pretext. This shows he had enough cooling time and provocation was neither grave nor sudden and that Nanavati had planned the murder. Moreover, according to the testimony of Ahuja's servant, Anjani, who was present at the house during the occurrence of the incident and so, was a natural witness, testified that there were four shots consecutively in quick succession and the entire event occurred in less than a minute thereby ruling out scuffle. Nanavati walked out of Ahuja's residence, without explaining to his sister Mamie, who was present in another room of the flat that it was an accident. The deputy commissioner of police testified that Nanavati confessed that he had shot dead Ahuja and even corrected the misspelling of his name in the police record thereby showing Nanavati was not dazed.
The Supreme Court upheld that this was a clear case of premeditated murder and concurred with the decision of the High Court and sentenced him to life imprisonment for culpable homicide amounting to murder.
"""

data=text.replace("\ufeff","")

data[0:100]

model=Summarizer()

result=model(data,max_length=400,min_length=100)

full=''.join(result)

pprint(full)

from transformers import pipeline

summarizer = pipeline("summarization")

summarizer(full, max_length=150, min_length=100, do_sample=False)

model1 = Summarizer('distilbert-base-uncased')

import time
start = time.time()
resp=model(data)
end = time.time()

print(f'Response Time: {end-start}')
print(f'Summary: {resp}')

start1 = time.time()
resp1=model1(data)
end1 = time.time()

print(f'Response Time: {end1-start1}')
print(f'Summary: {resp1}')

start2 = time.time()
resp2=summarizer(data)
end2 = time.time()

print(f'Response Time: {end2-start2}')
print(f'Summary: {resp2}')

resp1

resp

resp2

